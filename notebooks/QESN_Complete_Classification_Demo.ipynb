{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QESN Complete Classification Demo (Adaptive 90-95% Accuracy Pipeline)\n",
    "\n",
    "This notebook rebuilds the end-to-end QESN-MABe classification workflow using the \n",
    "exported checkpoint (\u224892.6% accuracy) and the adaptive optimisation plan described in\n",
    "`Mejorar_Precision_Modelo_Cuantico.md`.\\n",
    "\\n",
    "It is designed to run against the new exposure dataset and report production-grade metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "\n",
    "- Cargar el modelo exportado (`model_weights.bin`, `model_config.json`) y validar paridad.\n",
    "- Aplicar limpieza y balanceo temporal sobre el dataset de exposici\u00f3n.\n",
    "- Introducir ajustes f\u00edsicos adaptativos (dt y energ\u00eda) antes de cada ventana.\n",
    "- Evaluar accuracy, macro-F1 y matriz de confusi\u00f3n para las 37 clases.\n",
    "- Generar reportes listos para las demos profesionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importaciones y Configuraci\u00f3n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom pathlib import Path\nfrom dataclasses import dataclass\nfrom typing import Dict, Iterable, List, Optional, Tuple\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n\nfrom python.model_loader import load_inference\nfrom python.qesn_inference import QESNInference  # compat for type hints\n\nplt.rcParams['figure.figsize'] = (12, 7)\nplt.rcParams['figure.dpi'] = 140\nplt.rcParams['font.size'] = 10\nsns.set_theme(style='whitegrid', palette='husl')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rutas y Carga del Modelo\n",
    "\n",
    "Ajusta las variables de entorno `QESN_MODEL_DIR` y `QESN_DATASET_ROOT` para personalizar los paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "MODEL_DIR = os.getenv('QESN_MODEL_DIR')\nDATASET_ROOT = Path(os.getenv('QESN_DATASET_ROOT', 'data/exposure_dataset'))\nTRACKING_DIR = DATASET_ROOT / 'tracking'\nLABELS_CSV = DATASET_ROOT / 'labels.csv'\n\nprint('Model directory   :', MODEL_DIR or '(using default kaggle_model/)')\nprint('Dataset root      :', DATASET_ROOT)\nprint('Tracking parquet  :', TRACKING_DIR)\nprint('Labels CSV        :', LABELS_CSV)\n\n# Cargar inferencia base\nbase_model = load_inference(MODEL_DIR)\nprint('\nModelo cargado:')\nprint('  grid      :', base_model.grid_width, 'x', base_model.grid_height)\nprint('  window    :', base_model.window_size)\nprint('  stride    :', base_model.stride)\nprint('  clases    :', len(base_model.class_names))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Utilidades de Carga y Limpieza de Datos\n",
    "\n",
    "Las funciones siguientes asumen el formato est\u00e1ndar MABe: un `labels.csv` con columnas `video_id`, `frame`, `behavior` y un directorio de `parquet` con keypoints (`frame`, `track_id`, `keypoint`, `x`, `y`, `confidence`). Adapta las funciones si tu dataset tiene cambios de esquema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "MABE_BEHAVIORS = base_model.class_names\nNUM_BEHAVIORS = len(MABE_BEHAVIORS)\nKEYPOINTS_PER_MOUSE = 18\nMICE_PER_FRAME = 4\n\n@dataclass\nclass WindowSample:\n    video_id: str\n    start_frame: int\n    end_frame: int\n    keypoints: np.ndarray  # shape: (frames, mice, keypoints, 3)\n    true_label: int\n\ndef load_labels(labels_csv: Path) -> pd.DataFrame:\n    if not labels_csv.exists():\n        raise FileNotFoundError(f'Archivo de etiquetas no encontrado: {labels_csv}')\n    df = pd.read_csv(labels_csv)\n    required = {'video_id', 'frame', 'behavior'}\n    missing = required - set(df.columns)\n    if missing:\n        raise ValueError(f'Faltan columnas en labels.csv: {missing}')\n    df['behavior'] = df['behavior'].astype(str)\n    df = df[df['behavior'].isin(MABE_BEHAVIORS)].copy()\n    return df\n\ndef load_tracking(video_id: str) -> pd.DataFrame:\n    parquet_path = TRACKING_DIR / f'{video_id}.parquet'\n    if not parquet_path.exists():\n        raise FileNotFoundError(f'No existe el parquet de tracking: {parquet_path}')\n    return pd.read_parquet(parquet_path)\n\ndef reshape_keypoints(df: pd.DataFrame) -> np.ndarray:\n    required = {'frame', 'track_id', 'keypoint', 'x', 'y', 'confidence'}\n    missing = required - set(df.columns)\n    if missing:\n        raise ValueError(f'Faltan columnas en tracking: {missing}')\n    frames = int(df['frame'].max()) + 1\n    kp_array = np.full((frames, MICE_PER_FRAME, KEYPOINTS_PER_MOUSE, 3), np.nan, dtype=np.float32)\n    grouped = df.groupby(['frame', 'track_id', 'keypoint'])\n    for (frame, track, kp), row in grouped:\n        if track >= MICE_PER_FRAME or kp >= KEYPOINTS_PER_MOUSE:\n            continue\n        kp_array[frame, track, kp, 0] = row['x']\n        kp_array[frame, track, kp, 1] = row['y']\n        kp_array[frame, track, kp, 2] = row['confidence']\n    return kp_array\n\ndef interpolate_missing(keypoints: np.ndarray) -> np.ndarray:\n    mask = np.isnan(keypoints)\n    if not mask.any():\n        return keypoints\n    filled = np.copy(keypoints)\n    for axis in range(3):\n        data = filled[..., axis]\n        missing = np.isnan(data)\n        if missing.any():\n            idx = np.arange(data.shape[0])\n            for mouse in range(data.shape[1]):\n                for kp in range(data.shape[2]):\n                    series = data[:, mouse, kp]\n                    miss = np.isnan(series)\n                    if miss.all():\n                        continue\n                    valid_idx = idx[~miss]\n                    valid_vals = series[~miss]\n                    series[miss] = np.interp(idx[miss], valid_idx, valid_vals)\n                    data[:, mouse, kp] = series\n    filled[..., 2] = np.clip(filled[..., 2], 0.0, 1.0)\n    return filled\n\ndef compute_window_label(labels_df: pd.DataFrame, video_id: str, start: int, end: int) -> Optional[int]:\n    window_labels = labels_df[(labels_df['video_id'] == video_id) & (labels_df['frame'] >= start) & (labels_df['frame'] < end)]\n    if window_labels.empty:\n        return None\n    counts = window_labels['behavior'].value_counts()\n    return MABE_BEHAVIORS.index(counts.idxmax())\n\ndef iter_windows(keypoints: np.ndarray, window: int, stride: int) -> Iterable[Tuple[int, int, np.ndarray]]:\n    total_frames = keypoints.shape[0]\n    for start in range(0, total_frames - window + 1, stride):\n        end = start + window\n        yield start, end, keypoints[start:end]\n\ndef generate_samples(video_id: str, keypoints: np.ndarray, labels_df: pd.DataFrame, window: int, stride: int) -> List[WindowSample]:\n    samples: List[WindowSample] = []\n    for start, end, chunk in iter_windows(keypoints, window, stride):\n        label = compute_window_label(labels_df, video_id, start, end)\n        if label is None:\n            continue\n        samples.append(WindowSample(video_id, start, end, chunk, label))\n    return samples"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelo Adaptativo\n",
    "\n",
    "Implementamos un contenedor que ajusta `dt`, `energy_injection` y `coupling_strength` seg\u00fan la cinem\u00e1tica de cada ventana antes de delegar en `QESNInference`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveQESN:\n",
    "    def __init__(self, model: QESNInference):\n",
    "        self.model = model\n",
    "\n",
    "    @staticmethod\n",
    "    def _window_stats(keypoints: np.ndarray) -> Dict[str, float]:\n",
    "        displacements = np.diff(keypoints[..., :2], axis=0)\n",
    "        speeds = np.linalg.norm(displacements, axis=-1)\n",
    "        mean_speed = np.nanmean(speeds) if speeds.size else 0.0\n",
    "        max_speed = np.nanmax(speeds) if speeds.size else 0.0\n",
    "        valid_ratio = np.mean(keypoints[..., 2] > 0.5)\n",
    "        return {\n",
    "            'mean_speed': float(np.nan_to_num(mean_speed)),\n",
    "            'max_speed': float(np.nan_to_num(max_speed)),\n",
    "            'valid_ratio': float(np.nan_to_num(valid_ratio))\n",
    "        }\n",
    "\n",
    "    def _configure_physics(self, stats: Dict[str, float]):\n",
    "        base_coupling = 0.5\n",
    "        coupling = np.clip(base_coupling + 0.05 * (stats['mean_speed'] / 15.0 - 0.5), 0.45, 0.52)\n",
    "        diffusion = np.clip(coupling, 0.45, 0.52)\n",
    "        dt = 0.0015 if stats['max_speed'] > 25.0 else 0.0020\n",
    "        energy = 0.05 * np.clip(0.8 + stats['valid_ratio'], 0.9, 1.1)\n",
    "        if stats['valid_ratio'] < 0.6:\n",
    "            energy *= 1.1\n",
    "        self.model.foam.setCouplingStrength(coupling)\n",
    "        self.model.foam.setDiffusionRate(diffusion)\n",
    "        self.model.foam.setDecayRate(0.001)\n",
    "        self.model.dt = dt\n",
    "        self.model.energy_injection = energy\n",
    "\n",
    "    def predict_window(self, window: WindowSample, video_width: int, video_height: int):\n",
    "        stats = self._window_stats(window.keypoints)\n",
    "        self._configure_physics(stats)\n",
    "        pred_idx, probs, pred_name = self.model.predict(window.keypoints, video_width, video_height, window_size=self.model.window_size)\n",
    "        return {\n",
    "            'video_id': window.video_id,\n",
    "            'start': window.start_frame,\n",
    "            'end': window.end_frame,\n",
    "            'pred_idx': int(pred_idx),\n",
    "            'pred_name': pred_name,\n",
    "            'probabilities': probs,\n",
    "            'stats': stats\n",
    "        }\n",
    "\n",
    "adaptive_model = AdaptiveQESN(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluaci\u00f3n del Dataset\n",
    "\n",
    "La funci\u00f3n `evaluate_dataset` recorre todos los videos, genera ventanas de 60 frames (stride 30) y calcula accuracy/macro-F1. Ajusta `max_videos` para reducir tiempo durante depuraci\u00f3n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def evaluate_dataset(labels_df: pd.DataFrame, max_videos: Optional[int] = None) -> Dict[str, object]:\n    if not TRACKING_DIR.exists():\n        raise FileNotFoundError(f'Directorio de tracking no disponible: {TRACKING_DIR}')\n    video_ids = sorted(labels_df['video_id'].unique())\n    if max_videos:\n        video_ids = video_ids[:max_videos]\n\n    y_true: List[int] = []\n    y_pred: List[int] = []\n    records: List[Dict[str, object]] = []\n\n    for video_id in tqdm(video_ids, desc='Evaluating videos'):\n        tracking_df = load_tracking(video_id)\n        keypoints = reshape_keypoints(tracking_df)\n        keypoints = interpolate_missing(keypoints)\n        samples = generate_samples(video_id, keypoints, labels_df, base_model.window_size, base_model.stride)\n        if not samples:\n            continue\n        video_width = int(np.nanmax(keypoints[..., 0]))\n        video_height = int(np.nanmax(keypoints[..., 1]))\n        for sample in samples:\n            result = adaptive_model.predict_window(sample, video_width, video_height)\n            y_true.append(sample.true_label)\n            y_pred.append(result['pred_idx'])\n            records.append({\n                'video_id': video_id,\n                'start_frame': sample.start_frame,\n                'end_frame': sample.end_frame,\n                'true_label': sample.true_label,\n                'pred_label': result['pred_idx'],\n                'true_behavior': MABE_BEHAVIORS[sample.true_label],\n                'pred_behavior': result['pred_name'],\n                'confidence': float(result['probabilities'][result['pred_idx']]),\n                'mean_speed': result['stats']['mean_speed'],\n                'max_speed': result['stats']['max_speed'],\n                'valid_ratio': result['stats']['valid_ratio']\n            })\n\n    if not y_true:\n        raise RuntimeError('No se generaron ventanas con etiquetas v\u00e1lidas.')\n\n    accuracy = accuracy_score(y_true, y_pred)\n    macro_f1 = f1_score(y_true, y_pred, average='macro')\n    report = classification_report(y_true, y_pred, target_names=MABE_BEHAVIORS, digits=3)\n    cm = confusion_matrix(y_true, y_pred, labels=list(range(NUM_BEHAVIORS)))\n    results_df = pd.DataFrame.from_records(records)\n\n    return {\n        'accuracy': accuracy,\n        'macro_f1': macro_f1,\n        'report': report,\n        'confusion_matrix': cm,\n        'predictions': results_df\n    }"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ejecutar Evaluaci\u00f3n\n",
    "\n",
    "Si a\u00fan no tienes el dataset preparado, ejecuta primero el pipeline de extracci\u00f3n. Ajusta `max_videos` para pruebas r\u00e1pidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "labels_df = load_labels(LABELS_CSV)\nprint(f'Videos disponibles: {labels_df.video_id.nunique()}')\nprint(labels_df.head())\n\n# Cambia max_videos a None para procesar todo el dataset\nEVAL_RESULTS = evaluate_dataset(labels_df, max_videos=None)\nprint(f\"Accuracy: {EVAL_RESULTS['accuracy']*100:.2f}%\")\nprint(f\"Macro F1: {EVAL_RESULTS['macro_f1']*100:.2f}%\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_conf_df = EVAL_RESULTS['predictions'][EVAL_RESULTS['predictions'].confidence < 0.10]\n",
    "print(f'Bajas confianzas detectadas: {len(low_conf_df)} ventanas')\n",
    "display(low_conf_df[['video_id', 'start_frame', 'end_frame', 'true_behavior', 'pred_behavior', 'confidence', 'valid_ratio', 'mean_speed']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizaci\u00f3n de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p",
    "r",
    "e",
    "d",
    "_",
    "d",
    "f",
    " ",
    "=",
    " ",
    "E",
    "V",
    "A",
    "L",
    "_",
    "R",
    "E",
    "S",
    "U",
    "L",
    "T",
    "S",
    "[",
    "'",
    "p",
    "r",
    "e",
    "d",
    "i",
    "c",
    "t",
    "i",
    "o",
    "n",
    "s",
    "'",
    "]",
    "\n",
    "c",
    "m",
    " ",
    "=",
    " ",
    "E",
    "V",
    "A",
    "L",
    "_",
    "R",
    "E",
    "S",
    "U",
    "L",
    "T",
    "S",
    "[",
    "'",
    "c",
    "o",
    "n",
    "f",
    "u",
    "s",
    "i",
    "o",
    "n",
    "_",
    "m",
    "a",
    "t",
    "r",
    "i",
    "x",
    "'",
    "]",
    "\n",
    "\n",
    "f",
    "i",
    "g",
    ",",
    " ",
    "a",
    "x",
    " ",
    "=",
    " ",
    "p",
    "l",
    "t",
    ".",
    "s",
    "u",
    "b",
    "p",
    "l",
    "o",
    "t",
    "s",
    "(",
    "f",
    "i",
    "g",
    "s",
    "i",
    "z",
    "e",
    "=",
    "(",
    "1",
    "4",
    ",",
    " ",
    "1",
    "2",
    ")",
    ")",
    "\n",
    "s",
    "n",
    "s",
    ".",
    "h",
    "e",
    "a",
    "t",
    "m",
    "a",
    "p",
    "(",
    "c",
    "m",
    ",",
    " ",
    "a",
    "x",
    "=",
    "a",
    "x",
    ",",
    " ",
    "c",
    "m",
    "a",
    "p",
    "=",
    "'",
    "v",
    "i",
    "r",
    "i",
    "d",
    "i",
    "s",
    "'",
    ",",
    " ",
    "l",
    "i",
    "n",
    "e",
    "w",
    "i",
    "d",
    "t",
    "h",
    "s",
    "=",
    "0",
    ".",
    "1",
    ",",
    " ",
    "l",
    "i",
    "n",
    "e",
    "c",
    "o",
    "l",
    "o",
    "r",
    "=",
    "'",
    "g",
    "r",
    "a",
    "y",
    "'",
    ",",
    " ",
    "c",
    "b",
    "a",
    "r",
    "=",
    "T",
    "r",
    "u",
    "e",
    ",",
    " ",
    "s",
    "q",
    "u",
    "a",
    "r",
    "e",
    "=",
    "T",
    "r",
    "u",
    "e",
    ")",
    "\n",
    "a",
    "x",
    ".",
    "s",
    "e",
    "t",
    "_",
    "t",
    "i",
    "t",
    "l",
    "e",
    "(",
    "'",
    "C",
    "o",
    "n",
    "f",
    "u",
    "s",
    "i",
    "o",
    "n",
    " ",
    "M",
    "a",
    "t",
    "r",
    "i",
    "x",
    " ",
    "-",
    " ",
    "Q",
    "E",
    "S",
    "N",
    " ",
    "A",
    "d",
    "a",
    "p",
    "t",
    "i",
    "v",
    "e",
    " ",
    "I",
    "n",
    "f",
    "e",
    "r",
    "e",
    "n",
    "c",
    "e",
    "'",
    ")",
    "\n",
    "a",
    "x",
    ".",
    "s",
    "e",
    "t",
    "_",
    "x",
    "l",
    "a",
    "b",
    "e",
    "l",
    "(",
    "'",
    "P",
    "r",
    "e",
    "d",
    "i",
    "c",
    "t",
    "e",
    "d",
    "'",
    ")",
    "\n",
    "a",
    "x",
    ".",
    "s",
    "e",
    "t",
    "_",
    "y",
    "l",
    "a",
    "b",
    "e",
    "l",
    "(",
    "'",
    "T",
    "r",
    "u",
    "e",
    "'",
    ")",
    "\n",
    "a",
    "x",
    ".",
    "s",
    "e",
    "t",
    "_",
    "x",
    "t",
    "i",
    "c",
    "k",
    "s",
    "(",
    "n",
    "p",
    ".",
    "a",
    "r",
    "a",
    "n",
    "g",
    "e",
    "(",
    "N",
    "U",
    "M",
    "_",
    "B",
    "E",
    "H",
    "A",
    "V",
    "I",
    "O",
    "R",
    "S",
    ")",
    " ",
    "+",
    " ",
    "0",
    ".",
    "5",
    ")",
    "\n",
    "a",
    "x",
    ".",
    "s",
    "e",
    "t",
    "_",
    "x",
    "t",
    "i",
    "c",
    "k",
    "l",
    "a",
    "b",
    "e",
    "l",
    "s",
    "(",
    "M",
    "A",
    "B",
    "E",
    "_",
    "B",
    "E",
    "H",
    "A",
    "V",
    "I",
    "O",
    "R",
    "S",
    ",",
    " ",
    "r",
    "o",
    "t",
    "a",
    "t",
    "i",
    "o",
    "n",
    "=",
    "9",
    "0",
    ")",
    "\n",
    "a",
    "x",
    ".",
    "s",
    "e",
    "t",
    "_",
    "y",
    "t",
    "i",
    "c",
    "k",
    "s",
    "(",
    "n",
    "p",
    ".",
    "a",
    "r",
    "a",
    "n",
    "g",
    "e",
    "(",
    "N",
    "U",
    "M",
    "_",
    "B",
    "E",
    "H",
    "A",
    "V",
    "I",
    "O",
    "R",
    "S",
    ")",
    " ",
    "+",
    " ",
    "0",
    ".",
    "5",
    ")",
    "\n",
    "a",
    "x",
    ".",
    "s",
    "e",
    "t",
    "_",
    "y",
    "t",
    "i",
    "c",
    "k",
    "l",
    "a",
    "b",
    "e",
    "l",
    "s",
    "(",
    "M",
    "A",
    "B",
    "E",
    "_",
    "B",
    "E",
    "H",
    "A",
    "V",
    "I",
    "O",
    "R",
    "S",
    ",",
    " ",
    "r",
    "o",
    "t",
    "a",
    "t",
    "i",
    "o",
    "n",
    "=",
    "0",
    ")",
    "\n",
    "p",
    "l",
    "t",
    ".",
    "t",
    "i",
    "g",
    "h",
    "t",
    "_",
    "l",
    "a",
    "y",
    "o",
    "u",
    "t",
    "(",
    ")",
    "\n",
    "p",
    "l",
    "t",
    ".",
    "s",
    "h",
    "o",
    "w",
    "(",
    ")",
    "\n",
    "\n",
    "p",
    "l",
    "t",
    ".",
    "f",
    "i",
    "g",
    "u",
    "r",
    "e",
    "(",
    "f",
    "i",
    "g",
    "s",
    "i",
    "z",
    "e",
    "=",
    "(",
    "1",
    "0",
    ",",
    " ",
    "4",
    ")",
    ")",
    "\n",
    "s",
    "n",
    "s",
    ".",
    "h",
    "i",
    "s",
    "t",
    "p",
    "l",
    "o",
    "t",
    "(",
    "p",
    "r",
    "e",
    "d",
    "_",
    "d",
    "f",
    "[",
    "'",
    "c",
    "o",
    "n",
    "f",
    "i",
    "d",
    "e",
    "n",
    "c",
    "e",
    "'",
    "]",
    ",",
    " ",
    "b",
    "i",
    "n",
    "s",
    "=",
    "3",
    "0",
    ",",
    " ",
    "k",
    "d",
    "e",
    "=",
    "T",
    "r",
    "u",
    "e",
    ")",
    "\n",
    "p",
    "l",
    "t",
    ".",
    "t",
    "i",
    "t",
    "l",
    "e",
    "(",
    "'",
    "D",
    "i",
    "s",
    "t",
    "r",
    "i",
    "b",
    "u",
    "t",
    "i",
    "o",
    "n",
    " ",
    "o",
    "f",
    " ",
    "P",
    "r",
    "e",
    "d",
    "i",
    "c",
    "t",
    "i",
    "o",
    "n",
    " ",
    "C",
    "o",
    "n",
    "f",
    "i",
    "d",
    "e",
    "n",
    "c",
    "e",
    "'",
    ")",
    "\n",
    "p",
    "l",
    "t",
    ".",
    "x",
    "l",
    "a",
    "b",
    "e",
    "l",
    "(",
    "'",
    "c",
    "o",
    "n",
    "f",
    "i",
    "d",
    "e",
    "n",
    "c",
    "e",
    "'",
    ")",
    "\n",
    "p",
    "l",
    "t",
    ".",
    "y",
    "l",
    "a",
    "b",
    "e",
    "l",
    "(",
    "'",
    "c",
    "o",
    "u",
    "n",
    "t",
    "'",
    ")",
    "\n",
    "p",
    "l",
    "t",
    ".",
    "t",
    "i",
    "g",
    "h",
    "t",
    "_",
    "l",
    "a",
    "y",
    "o",
    "u",
    "t",
    "(",
    ")",
    "\n",
    "p",
    "l",
    "t",
    ".",
    "s",
    "h",
    "o",
    "w",
    "(",
    ")",
    "\n",
    "\n",
    "p",
    "r",
    "i",
    "n",
    "t",
    "(",
    "'",
    "C",
    "l",
    "a",
    "s",
    "s",
    "i",
    "f",
    "i",
    "c",
    "a",
    "t",
    "i",
    "o",
    "n",
    " ",
    "R",
    "e",
    "p",
    "o",
    "r",
    "t",
    ":",
    "\n",
    "'",
    ")",
    "\n",
    "p",
    "r",
    "i",
    "n",
    "t",
    "(",
    "E",
    "V",
    "A",
    "L",
    "_",
    "R",
    "E",
    "S",
    "U",
    "L",
    "T",
    "S",
    "[",
    "'",
    "r",
    "e",
    "p",
    "o",
    "r",
    "t",
    "'",
    "]",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Persistencia y Reporting\n",
    "\n",
    "Guarda los resultados para integrarlos con los demos multimedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "OUTPUT_DIR = DATASET_ROOT / 'results'\nOUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n\npred_path = OUTPUT_DIR / 'qesn_adaptive_predictions.parquet'\nreport_path = OUTPUT_DIR / 'qesn_classification_report.txt'\ncm_path = OUTPUT_DIR / 'qesn_confusion_matrix.npy'\n\npred_df.to_parquet(pred_path, index=False)\nnp.save(cm_path, EVAL_RESULTS['confusion_matrix'])\nwith open(report_path, 'w', encoding='utf-8') as f:\n    f.write(f\"Accuracy: {EVAL_RESULTS['accuracy']*100:.3f}%\\n\")\n    f.write(f\"Macro F1: {EVAL_RESULTS['macro_f1']*100:.3f}%\\n\\n\")\n    f.write(EVAL_RESULTS['report'])\n\nprint('Resultados guardados en:', OUTPUT_DIR)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Pr\u00f3ximos Pasos\n",
    "\n",
    "- Repetir la evaluaci\u00f3n con validaci\u00f3n cruzada (3 folds) si se requiere certificaci\u00f3n.\n",
    "- Ajustar los par\u00e1metros adaptativos (`dt`, energ\u00eda, coupling) seg\u00fan el an\u00e1lisis de los resultados guardados en `results/`.\n",
    "- Integrar estos artefactos en los demos (`demo_espectacular.py`, notebooks profesionales)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}